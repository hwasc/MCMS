{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Unit2.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"73d_9Tb27UqM"},"source":["# Unit 2: Some extra material on eigenvalues and eigenvectors"]},{"cell_type":"code","metadata":{"id":"oKkBJX8j7UqQ"},"source":["import numpy as np\n","from numpy.random import rand"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PYm1ZD197UqT"},"source":["Let's create a small 2x2 random matrix. "]},{"cell_type":"code","metadata":{"id":"7GHmq4w87UqT"},"source":["M=rand(2,2)\n","print(M)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mRt2nLKM7UqT"},"source":["This being a 2x2 matrix, there will be two eigenvalues $\\lambda_i$ and two eigenvectors $\\textbf{v}_i$. Let's find them out starting from the definition. If $\\lambda_i$ and $v_i$ are eigenvalues and eigenvectors respectively then: $M\\textbf{v}_i=\\lambda_i\\textbf{v}_i$. We can form a vector $\\boldsymbol{\\lambda}$ of these eigenvalues and a matrix $v$ of these eigenvectors and write: $Mv=\\boldsymbol{\\lambda}v$, which is also: $\\left(M-\\boldsymbol{\\lambda I}\\right)v=0$. Note how each vector of $v$ is transformed into the null vector. This says something about the determinant of the 'transformation' which is implemented by $\\left(M-\\boldsymbol{\\lambda I}\\right)$ and so we can find out the eigenvalues by calculating the determinant of the transformation, which must be 0. This leads to the so-called 'characteristic polynomial', which in the 2x2 case is: $\\lambda^2-tr(M)\\lambda+det(M)=0$ and leads to two solutions (which may be complex): $\\lambda=\\frac{tr(M)\\pm\\sqrt{tr(M)^2-4det(M)}}{2}$."]},{"cell_type":"code","metadata":{"id":"apUwrlI67UqU"},"source":["lambda1=0.5*(np.trace(M)+np.sqrt(np.trace(M)**2-4*np.linalg.det(M)))\n","lambda2=0.5*(np.trace(M)-np.sqrt(np.trace(M)**2-4*np.linalg.det(M)))\n","print('Eigenvalues are: %f and %f' % (lambda1, lambda2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TLHidG1j7UqU"},"source":["Let's verify this against Python's implementation"]},{"cell_type":"code","metadata":{"id":"lhyaDgqI7UqV"},"source":["(w,v)=np.linalg.eig(M)\n","print('Eigenvalues are: %f and %f' % (w[0],w[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XPy8tCq47UqV"},"source":["## Behaviour of power of matrix"]},{"cell_type":"markdown","metadata":{"id":"V1-LXwUA7UqW"},"source":["You will remember that a matrix implements a rotation followed by some scaling, followed by some rotation. Eigenvectors and eigenvalues make it possible to represent this quite neatly. Keeping previous notations (well, almost, now I use $\\boldsymbol{\\lambda}$ to denote $\\boldsymbol{\\lambda}I$, you can write: $M=v\\boldsymbol{\\lambda}v^{-1}$. Let's check that it is true numericall. "]},{"cell_type":"code","metadata":{"id":"VDnpW5au7UqW"},"source":["print(np.matrix(v)*np.matrix(np.diag(w))*np.matrix(np.linalg.inv(v)))\n","print(M)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v5PvePA87UqX"},"source":["OK now what is M^d? Well, it's simply: $v\\boldsymbol{\\lambda}^dv^{-1}$. The $\\lambda$ matrix is diagonal so its power is simply the power of the diagonal terms, i.e., the eigenvalues. Let's check numerically (with d=10): "]},{"cell_type":"code","metadata":{"id":"fRHd3am57UqX"},"source":["print(np.matrix(M)**10)\n","print(np.matrix(v)*np.matrix(np.diag(w))**10*np.matrix(np.linalg.inv(v)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20KTkgRu7UqX"},"source":[""],"execution_count":null,"outputs":[]}]}